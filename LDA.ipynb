{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A técnica de LDA executada por Barbosa, necessita dividir o dataset resultante com pelo sentimento no qual eles foram identificados. Assim a as próximas iterações do algoritmo serão aplicadas em um grupo positivo, negativo e neutro, separadamente, por conta do desbalanceamento do dataset. Se utilizado como um todo, esta parte do experimento estaria enviesada, por conta de haver muito mais comentários positivos do que os outros, o que faria apenas respostas positivas serem mostradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import os\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pyLDAvis.gensim\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "\n",
    "# number of topics\n",
    "num_topics = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#carrega o dataset\n",
    "dataset = pd.read_csv('./Post Cleaning Datasets/dataset_1_no_stopword_stemm.csv')\n",
    "datasetLDA = dataset.copy()\n",
    "\n",
    "datasetLDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gambiarra pra transformar a lista de palavras em uma unica string kkkkkkkkkkkkk\n",
    "datasetLDA['comentarios'] = datasetLDA['comentarios'].apply(eval).apply(' '.join)\n",
    "\n",
    "datasetLDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the wordcloud library\n",
    "from wordcloud import WordCloud\n",
    "# Join the different processed titles together.\n",
    "long_string = ','.join(list(datasetLDA['comentarios'].values))\n",
    "# Create a WordCloud object\n",
    "wordcloud = WordCloud(background_color=\"white\", max_words=5000, contour_width=3, contour_color='steelblue')\n",
    "# Generate a word cloud\n",
    "wordcloud.generate(long_string)\n",
    "# Visualize the word cloud\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokeniza a coluna comentários e cria colunas com bigrams e trigrams\n",
    "datasetLDA['comentarios'] = datasetLDA['comentarios'].apply(word_tokenize)\n",
    "\n",
    "datasetLDA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carrega funções de bigram e trigram\n",
    "bigram = gensim.models.Phrases(datasetLDA['comentarios'], min_count=2, threshold=100, delimiter='_') # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[datasetLDA['comentarios']], threshold=100)\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Atualiza o dataset com bigrams e trigrams\n",
    "datasetLDA['comentarios'] = make_bigrams(datasetLDA['comentarios'])\n",
    "\n",
    "datasetLDA['comentarios'] = make_trigrams(datasetLDA['comentarios'])\n",
    "\n",
    "datasetLDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cria um dicionário de cada dataset, depois cria um corpus onde é feito o processo de Term Document Frequency, outra etapa necessária para a aplicação do LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# divide o dataset em 3, positivo, negativo e neutro\n",
    "grouped = datasetLDA.groupby(datasetLDA.sentimento)\n",
    "\n",
    "#cria dataframes para cada sentimento\n",
    "df_positive = grouped.get_group(\"positive\")\n",
    "df_negative = grouped.get_group(\"negative\")\n",
    "df_neutral = grouped.get_group(\"neutral\")\n",
    "\n",
    "# deleta a coluna 'sentimento' pois não é mais necessária para o experimento\n",
    "df_positive = df_positive.drop('sentimento', axis=1)\n",
    "df_negative = df_negative.drop('sentimento', axis=1)\n",
    "df_neutral = df_neutral.drop('sentimento', axis=1)\n",
    "\n",
    "\n",
    "df_positive.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criando o Dicionário, Corpus e TDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive_dic = corpora.Dictionary(df_positive['comentarios'])\n",
    "df_negative_dic = corpora.Dictionary(df_negative['comentarios'])\n",
    "df_neutral_dic = corpora.Dictionary(df_neutral['comentarios'])\n",
    "\n",
    "# Cria um corpus de cada dataset\n",
    "df_positive_corpus = df_positive['comentarios']\n",
    "df_negative_corpus = df_negative['comentarios']\n",
    "df_neutral_corpus = df_neutral['comentarios']\n",
    "\n",
    "# Term Document Frequency de cada corpus\n",
    "tdf_positive = [df_positive_dic.doc2bow(text) for text in df_positive_corpus]\n",
    "tdf_negative = [df_negative_dic.doc2bow(text) for text in df_negative_corpus]\n",
    "tdf_neutral = [df_neutral_dic.doc2bow(text) for text in df_neutral_corpus]\n",
    "\n",
    "\n",
    "pprint(df_positive_dic)\n",
    "# View\n",
    "pprint(tdf_positive)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando Lattent Dirilech Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Dataset Positivo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model_positive = gensim.models.LdaMulticore(corpus=tdf_positive,\n",
    "                                                id2word=df_positive_dic,\n",
    "                                                num_topics=num_topics,\n",
    "                                                passes=10,\n",
    "                                                per_word_topics=True)\n",
    "\n",
    "# Print the Keyword in the n topics\n",
    "pprint(lda_model_positive.print_topics())\n",
    "doc_lda = lda_model_positive[tdf_positive]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Dataset Negativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model_negative = gensim.models.LdaMulticore(corpus=tdf_negative,\n",
    "                                                id2word=df_negative_dic,\n",
    "                                                num_topics=num_topics,\n",
    "                                                passes=10,\n",
    "                                                per_word_topics=True)\n",
    "\n",
    "# Print the Keyword in the n topics\n",
    "pprint(lda_model_negative.print_topics())\n",
    "doc_lda = lda_model_negative[tdf_negative]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LDA Dataset Neutro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model_neutral = gensim.models.LdaMulticore(corpus=tdf_neutral,\n",
    "                                                id2word=df_neutral_dic,\n",
    "                                                num_topics=num_topics,\n",
    "                                                passes=10,\n",
    "                                                per_word_topics=True)\n",
    "\n",
    "# Print the Keyword in the n topics\n",
    "pprint(lda_model_neutral.print_topics())\n",
    "doc_lda = lda_model_neutral[tdf_neutral]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculos das métricas da LDA\n",
    "\n",
    "# POSITIVO\n",
    "print()\n",
    "print('Positive')  \n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_positive, texts=df_positive['comentarios'], dictionary=df_positive_dic, coherence='c_v')\n",
    "coherence_lda_positive = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda_positive)\n",
    "\n",
    "coherence_model_ldaTeste = CoherenceModel(model=lda_model_positive, texts=df_positive['comentarios'], dictionary=df_positive_dic, coherence='u_mass')\n",
    "coherence_lda_positiveTeste = coherence_model_ldaTeste.get_coherence()\n",
    "print('\\nCoherence Score u mass: ', coherence_lda_positiveTeste)\n",
    "\n",
    "\n",
    "#NEGATIVE\n",
    "print()\n",
    "print('Negative')  \n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_negative, texts=df_negative['comentarios'], dictionary=df_negative_dic, coherence='c_v')\n",
    "coherence_lda_negativo = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda_negativo)\n",
    "\n",
    "coherence_model_ldaTeste = CoherenceModel(model=lda_model_negative, texts=df_negative['comentarios'], dictionary=df_negative_dic, coherence='u_mass')\n",
    "coherence_lda_negativoTeste = coherence_model_ldaTeste.get_coherence()\n",
    "print('\\nCoherence Score u mass: ', coherence_lda_negativoTeste)\n",
    "\n",
    "\n",
    "#NEUTRAL\n",
    "print()\n",
    "print('Neutral')  \n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_neutral, texts=df_neutral['comentarios'], dictionary=df_neutral_dic, coherence='c_v')\n",
    "coherence_lda_neutral = coherence_model_lda.get_coherence()\n",
    "print('Coherence Score: ', coherence_lda_neutral)\n",
    "\n",
    "coherence_model_ldaTeste = CoherenceModel(model=lda_model_neutral, texts=df_neutral['comentarios'], dictionary=df_neutral_dic, coherence='u_mass')\n",
    "coherence_lda_neutralTeste = coherence_model_ldaTeste.get_coherence()\n",
    "print('\\nCoherence Score u mass: ', coherence_lda_neutralTeste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialização da visualização do LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('./LDA Results/visualLDA_Positive'+str(num_topics))\n",
    "\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model_positive, tdf_positive, df_positive_dic)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './LDA Results/visualLDA_Positive'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('./LDA Results/visualLDA_Negative'+str(num_topics))\n",
    "\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model_negative, tdf_negative, df_negative_dic)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "        \n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './LDA Results/visualLDA_Negative'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_data_filepath = os.path.join('./LDA Results/visualLDA_Neutral'+str(num_topics))\n",
    "\n",
    "# # this is a bit time consuming - make the if statement True\n",
    "# # if you want to execute visualization prep yourself\n",
    "\n",
    "if 1 == 1:\n",
    "    LDAvis_prepared = pyLDAvis.gensim.prepare(lda_model_neutral, tdf_neutral, df_neutral_dic)\n",
    "    with open(LDAvis_data_filepath, 'wb') as f:\n",
    "        pickle.dump(LDAvis_prepared, f)\n",
    "# load the pre-prepared pyLDAvis data from disk\n",
    "with open(LDAvis_data_filepath, 'rb') as f:\n",
    "    LDAvis_prepared = pickle.load(f)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './LDA Results/visualLDA_Neutral'+ str(num_topics) +'.html')\n",
    "LDAvis_prepared"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
