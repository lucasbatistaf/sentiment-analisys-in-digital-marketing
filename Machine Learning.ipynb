{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando os modelos de Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagOfWords(tokenized_dataset):\n",
    "    bow_model = CountVectorizer(ngram_range=(1,2))\n",
    "    bow_model.fit(tokenized_dataset[\"comentarios\"])\n",
    "\n",
    "    X_bow = normalize(bow_model.transform(tokenized_dataset[\"comentarios\"])).tocsr()\n",
    "    y_bow = tokenized_dataset[\"sentimento\"].to_numpy()\n",
    "\n",
    "    print(\"Bag of Words done\")\n",
    "\n",
    "    return X_bow, y_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Divisão dataset teste e treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitDataset(X_bow, y_bow):\n",
    "\n",
    "    # Split dataset para o Bag of Words 80% treino / 20% teste\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_bow, y_bow, train_size=0.8)\n",
    "\n",
    "    print(\"Dataset Split done\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Folds Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kFoldsCV(X_bow, y_bow):\n",
    "\n",
    "    kf = KFold(n_splits=5)\n",
    "\n",
    "    for train_index, test_index in kf.split(X_bow):        \n",
    "        X_train_cv, X_test_cv = X_bow[train_index], X_bow[test_index]\n",
    "        y_train_cv, y_test_cv = y_bow[train_index], y_bow[test_index]\n",
    "    \n",
    "    print(\"k Folds done\")\n",
    "\n",
    "    return X_train_cv, X_test_cv, y_train_cv, y_test_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicação dos Machine Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showCnfMat(y_true,y_pred):\n",
    "    mat = confusion_matrix(y_true,y_pred)\n",
    "    for arr in mat:\n",
    "        print(\" \".join(list(map(str, arr))))\n",
    "        \n",
    "def plotHyperparameterScores(values,scores,scoring=\"accuracy\",parameter=\"Lamda\"):\n",
    "    if(scoring==\"f1\"):\n",
    "        bestScore = min(scores)\n",
    "    elif(scoring==\"accuracy\"):\n",
    "        bestScore = max(scores)\n",
    "    index = scores.index(bestScore)\n",
    "    val = values[index]\n",
    "    plt.plot(values,scores)\n",
    "    plt.show()\n",
    "    print(f\"Best Score at {parameter}: {val}\")\n",
    "    return val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticRegression(X_train, X_train_cv, X_test, y_train, y_train_cv, y_test, datasetName):\n",
    "    \n",
    "    C_values=[10**-1,10**0,10**1,10**2,10**4,10**5,10**6]\n",
    "    cv_scores = []\n",
    "\n",
    "    for C in C_values:\n",
    "        LR = LogisticRegression(C=C, solver=\"liblinear\",multi_class=\"auto\", dual=False)\n",
    "        LR.fit(X_train,y_train)\n",
    "        y_pred = LR.predict(X_train_cv)\n",
    "        cv_scores.append(accuracy_score(y_train_cv,y_pred))\n",
    "        \n",
    "    optimal_C = plotHyperparameterScores(C_values,cv_scores,\"accuracy\",\"C\")\n",
    "    LR_model = LogisticRegression(C=optimal_C, solver=\"liblinear\",multi_class=\"auto\", dual=False)\n",
    "    LR_model.fit(X_train, y_train)\n",
    "\n",
    "    y_predTrain= LR_model.predict(X_train)\n",
    "    y_predTest = LR_model.predict(X_test)\n",
    "    \n",
    "    pipeline = make_pipeline(StandardScaler(with_mean=False), LogisticRegression(C=optimal_C, solver=\"liblinear\",multi_class=\"auto\", dual=False))\n",
    "    \n",
    "    accCVTrain = cross_val_score(pipeline, X=X_train, y=y_train, cv=5, n_jobs=1)\n",
    "\n",
    "    \n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(y_train, y_predTrain, labels=['positive', 'negative', 'neutral'])\n",
    "    precisionTest,recallTest,fscoreTest,supportTest = precision_recall_fscore_support(y_test, y_predTest, labels=['positive', 'negative', 'neutral'])\n",
    "    \n",
    "    print('recall:  {0}'.format(precision))\n",
    "    print('recall:  {0}'.format(recall))\n",
    "    print('recall:  {0}'.format(fscore))\n",
    "    print('recall:  {0}'.format(support))\n",
    " \n",
    "    with open('./ML Results/Machine Learning Results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.writelines([datasetName, \", Logistic Regression, precision train data, \",str(precision),\",\\n\",\n",
    "                      datasetName, \", Logistic Regression, recall on train data, \",str(recall),\",\\n\",\n",
    "                      datasetName, \", Logistic Regression, f1-score train data, \",str(fscore),\",\\n\",\n",
    "                      datasetName, \", Logistic Regression, support train data, \",str(support),\",\\n\",\n",
    "                      datasetName, \", Logistic Regression, precision test data, \",str(precisionTest),\",\\n\",\n",
    "                      datasetName, \", Logistic Regression, recall test data, \",str(recallTest),\",\\n\",\n",
    "                      datasetName, \", Logistic Regression, f1-score test data, \",str(fscoreTest),\",\\n\",\n",
    "                      datasetName, \", Logistic Regression, support test data, \",str(supportTest),\",\\n\"])\n",
    "    \n",
    "    with open('./ML Results/Cross Validation Results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.writelines([datasetName, \", Logistic Regression, accuracy train data, \",str(accCVTrain),\",\\n\"])\n",
    "\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayes(X_train, X_train_cv, X_test, y_train, y_train_cv, y_test, datasetName):\n",
    "\n",
    "    alpha_values=[10**-3,10**-2,10**-1,10**0,10**1,10**2,10**3]\n",
    "    cv_scores = []\n",
    "\n",
    "    for alpha in alpha_values:\n",
    "        NB = MultinomialNB(alpha=alpha)\n",
    "        NB.fit(X_train,y_train)\n",
    "        y_pred = NB.predict(X_train_cv)\n",
    "        cv_scores.append(accuracy_score(y_train_cv,y_pred))\n",
    "        \n",
    "    optimal_alpha = plotHyperparameterScores(alpha_values,cv_scores,\"accuracy\",\"alpha\")\n",
    "    NB_model = MultinomialNB(alpha=optimal_alpha)\n",
    "    NB_model.fit(X_train, y_train)\n",
    "\n",
    "    y_predTrain= NB_model.predict(X_train)\n",
    "    y_predTest = NB_model.predict(X_test)\n",
    "    \n",
    "    pipeline = make_pipeline(StandardScaler(with_mean=False), MultinomialNB(alpha=optimal_alpha))\n",
    "\n",
    "    accCVTrain = cross_val_score(pipeline, X=X_train, y=y_train, cv=5, n_jobs=1)\n",
    "    \n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(y_train, y_predTrain, labels=['positive', 'negative', 'neutral'])\n",
    "    precisionTest,recallTest,fscoreTest,supportTest = precision_recall_fscore_support(y_test, y_predTest, labels=['positive', 'negative', 'neutral'])\n",
    "    \n",
    "    print('recall:  {0}'.format(precision))\n",
    "    print('recall:  {0}'.format(recall))\n",
    "    print('recall:  {0}'.format(fscore))\n",
    "    print('recall:  {0}'.format(support))\n",
    " \n",
    "    with open('./ML Results/Machine Learning Results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.writelines([datasetName, \", Naive Bayes, precision train data, \",str(precision),\",\\n\",\n",
    "                      datasetName, \", Naive Bayes, recall on train data, \",str(recall),\",\\n\",\n",
    "                      datasetName, \", Naive Bayes, f1-score train data, \",str(fscore),\",\\n\",\n",
    "                      datasetName, \", Naive Bayes, support train data, \",str(support),\",\\n\",\n",
    "                      datasetName, \", Naive Bayes, precision test data, \",str(precisionTest),\",\\n\",\n",
    "                      datasetName, \", Naive Bayes, recall test data, \",str(recallTest),\",\\n\",\n",
    "                      datasetName, \", Naive Bayes, f1-score test data, \",str(fscoreTest),\",\\n\",\n",
    "                      datasetName, \", Naive Bayes, support test data, \",str(supportTest),\",\\n\"])\n",
    "    \n",
    "    with open('./ML Results/Cross Validation Results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.writelines([datasetName, \", Naive Bayes, accuracy train data, \",str(accCVTrain),\",\\n\"])\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomForest(X_train, X_test, y_train, y_test, datasetName):\n",
    "\n",
    "    RF_model = RandomForestClassifier(n_estimators=30, n_jobs=-1)\n",
    "    RF_model.fit(X_train,y_train)\n",
    "\n",
    "    y_predTrain= RF_model.predict(X_train)\n",
    "    y_predTest = RF_model.predict(X_test)\n",
    "    \n",
    "    pipeline = make_pipeline(StandardScaler(with_mean=False), RandomForestClassifier(n_estimators=50, n_jobs=-1))\n",
    "\n",
    "    accCVTrain = cross_val_score(pipeline, X=X_train, y=y_train, cv=5, n_jobs=1)\n",
    "    \n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(y_train, y_predTrain, labels=['positive', 'negative', 'neutral'])\n",
    "    precisionTest,recallTest,fscoreTest,supportTest = precision_recall_fscore_support(y_test, y_predTest, labels=['positive', 'negative', 'neutral'])\n",
    "    \n",
    "    f1score = f1_score(y_test, y_predTest, average='weighted')\n",
    "\n",
    "    print('precisionTest:  {0}'.format(precisionTest))\n",
    "    print('recallTest:  {0}'.format(recallTest))\n",
    "    print('fscoreTest:  {0}'.format(fscoreTest))\n",
    "    print('supportTest:  {0}'.format(supportTest))\n",
    " \n",
    "    with open('./ML Results/Machine Learning Results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.writelines([datasetName, \", Random Forest, precision train data, \",str(precision),\",\\n\",\n",
    "                      datasetName, \", Random Forest, recall on train data, \",str(recall),\",\\n\",\n",
    "                      datasetName, \", Random Forest, f1-score train data, \",str(fscore),\",\\n\",\n",
    "                      datasetName, \", Random Forest, support train data, \",str(support),\",\\n\",\n",
    "                      datasetName, \", Random Forest, precision test data, \",str(precisionTest),\",\\n\",\n",
    "                      datasetName, \", Random Forest, recall test data, \",str(recallTest),\",\\n\",\n",
    "                      datasetName, \", Random Forest, f1-score test data, \",str(fscoreTest),\",\\n\",\n",
    "                      datasetName, \", Random Forest, support test data, \",str(supportTest),\",\\n\"])\n",
    "    \n",
    "    with open('./ML Results/Cross Validation Results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.writelines([datasetName, \", Random Forest, accuracy train data, \",str(accCVTrain),\",\\n\"])\n",
    "\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(X_train, X_train_cv, X_test, y_train, y_train_cv, y_test, datasetName):\n",
    "\n",
    "    C_values=[10**0,10,20,50,80,10**2,120,200,500]\n",
    "    cv_scores = []\n",
    "\n",
    "    for C in C_values:\n",
    "        SVM = LinearSVC(C = C, dual=False)\n",
    "        SVM.fit(X_train,y_train)\n",
    "        y_pred = SVM.predict(X_train_cv)\n",
    "        cv_scores.append(accuracy_score(y_train_cv,y_pred))\n",
    "        \n",
    "    optimal_C_SVM = plotHyperparameterScores(C_values,cv_scores,\"accuracy\",\"C\")\n",
    "    SVM_model = LinearSVC(C = optimal_C_SVM, dual=False)\n",
    "    SVM_model.fit(X_train, y_train)\n",
    "\n",
    "    y_predTrain= SVM_model.predict(X_train)\n",
    "    y_predTest = SVM_model.predict(X_test)\n",
    "    \n",
    "    pipeline = make_pipeline(StandardScaler(with_mean=False), LinearSVC(C = optimal_C_SVM, dual=False))\n",
    "    \n",
    "    accCVTrain = cross_val_score(pipeline, X=X_train, y=y_train, cv=5, n_jobs=1)\n",
    "    \n",
    "    precision,recall,fscore,support = precision_recall_fscore_support(y_train, y_predTrain, labels=['positive', 'negative', 'neutral'])\n",
    "    precisionTest,recallTest,fscoreTest,supportTest = precision_recall_fscore_support(y_test, y_predTest, labels=['positive', 'negative', 'neutral'])\n",
    "    \n",
    "    print('recall:  {0}'.format(precision))\n",
    "    print('recall:  {0}'.format(recall))\n",
    "    print('recall:  {0}'.format(fscore))\n",
    "    print('recall:  {0}'.format(support))\n",
    " \n",
    "    with open('./ML Results/Machine Learning Results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.writelines([datasetName, \", Support Vector, precision train data, \",str(precision),\",\\n\",\n",
    "                      datasetName, \", Support Vector, recall on train data, \",str(recall),\",\\n\",\n",
    "                      datasetName, \", Support Vector, f1-score train data, \",str(fscore),\",\\n\",\n",
    "                      datasetName, \", Support Vector, support train data, \",str(support),\",\\n\",\n",
    "                      datasetName, \", Support Vector, precision test data, \",str(precisionTest),\",\\n\",\n",
    "                      datasetName, \", Support Vector, recall test data, \",str(recallTest),\",\\n\",\n",
    "                      datasetName, \", Support Vector, f1-score test data, \",str(fscoreTest),\",\\n\",\n",
    "                      datasetName, \", Support Vector, support test data, \",str(supportTest),\",\\n\"])\n",
    "    \n",
    "    with open('./ML Results/Cross Validation Results.txt', 'a', encoding='utf-8') as f:\n",
    "        f.writelines([datasetName, \", Support Vector, accuracy train data, \",str(accCVTrain),\",\\n\"])\n",
    "\n",
    "\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estas células seguintes tem como objetivo aplicar os modelos de Machine Learning acima em todos os datasets que foram criados até o momento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pasta de origem dos datasets\n",
    "path = \"./Post Cleaning Datasets/\"\n",
    "\n",
    "#função que itera sobre todos os itens da pasta sobre os arquivos .csv que existem \n",
    "for entry in os.scandir(path):    \n",
    "    dataset = pd.read_csv(entry.path)  \n",
    "    print(\"Dataset:\", entry.name)\n",
    "\n",
    "    # Aplicando Bag of Words\n",
    "    X_bow, y_bow = bagOfWords(dataset)\n",
    "\n",
    "    #Dividindo os dados 80/20 e Kfolds\n",
    "    X_train, X_test, y_train, y_test = splitDataset(X_bow, y_bow)\n",
    "    X_train_cv, X_test_cv, y_train_cv, y_test_cv = kFoldsCV(X_bow, y_bow)\n",
    "\n",
    "    #Aplicando os Modelos ML\n",
    "    \n",
    "    print(\"Logistic Regression\")\n",
    "    #ogisticRegression(X_train, X_train_cv, X_test, y_train, y_train_cv, y_test, entry.name)\n",
    "    print(\"Logistic Regression done!\")\n",
    "    print()\n",
    "\n",
    "    print(\"Multinomial Naive Bayes\")\n",
    "    naiveBayes(X_train, X_train_cv, X_test, y_train, y_train_cv, y_test, entry.name)\n",
    "    print(\"Multinomial Naive Bayes done!\")\n",
    "    print()\n",
    "\n",
    "    print(\"Random Forest Classifier\")\n",
    "    randomForest(X_train, X_test, y_train, y_test, entry.name)\n",
    "    print(\"Random Forest Classifier done!\")\n",
    "    print()\n",
    "\n",
    "    print(\"Support Vector Machine\")\n",
    "    SVM(X_train, X_train_cv, X_test, y_train, y_train_cv, y_test, entry.name)\n",
    "    print(\"Support Vector Machine done!\")\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
